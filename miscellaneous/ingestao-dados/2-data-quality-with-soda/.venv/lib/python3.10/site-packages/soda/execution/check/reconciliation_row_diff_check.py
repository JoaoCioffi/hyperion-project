from typing import Dict

from deepdiff import DeepDiff
from deepdiff.helper import CannotCompare

from soda.execution.check.check import Check
from soda.execution.check_outcome import CheckOutcome
from soda.execution.metric.metric import Metric
from soda.execution.metric.reconciliation_row_diff_metric import (
    ReconciliationRowDiffMetric,
)
from soda.execution.table import Table
from soda.sampler.in_memory_sample import InMemorySample
from soda.sampler.sample_context import SampleContext
from soda.sampler.sampler import Sampler
from soda.sodacl.reconciliation_row_diff_check_cfg import ReconciliationRowDiffCheckCfg


class ReconciliationRowDiffCheck(Check):
    def __init__(
        self, check_cfg: ReconciliationRowDiffCheckCfg, data_source_scan: "DataSourceScan", partition: "Partition"
    ):
        super().__init__(check_cfg=check_cfg, data_source_scan=data_source_scan, partition=partition, column=None)
        self.check_cfg = check_cfg
        self.data_source_scan = data_source_scan
        self.partition = partition

        scan = data_source_scan.scan

        source_config = check_cfg.reconciliation_configurations["source"]
        target_config = check_cfg.reconciliation_configurations["target"]
        self.source_key_columns = check_cfg.source_key_columns
        self.target_key_columns = check_cfg.target_key_columns

        source_data_source_scan = scan._get_or_create_data_source_scan(source_config["datasource"])
        source_table: Table = source_data_source_scan.get_or_create_table(source_config["dataset"])
        source_partition = source_table.get_or_create_partition(None)
        source_filter = source_config.get("filter")

        target_data_source_scan = scan._get_or_create_data_source_scan(target_config["datasource"])
        target_table: Table = target_data_source_scan.get_or_create_table(target_config["dataset"])
        target_partition = target_table.get_or_create_partition(None)
        target_filter = target_config.get("filter")

        self.metrics = {}
        source_metric = ReconciliationRowDiffMetric(
            data_source_scan=source_data_source_scan,
            check=self,
            partition=source_partition,
            filter=source_filter,
            column=check_cfg.source_column,
        )
        target_metric = ReconciliationRowDiffMetric(
            data_source_scan=target_data_source_scan,
            check=self,
            partition=target_partition,
            filter=target_filter,
            column=check_cfg.target_column,
        )

        self.metrics["source_metric"] = source_data_source_scan.resolve_metric(source_metric)
        self.metrics["target_metric"] = target_data_source_scan.resolve_metric(target_metric)

    def evaluate(self, metrics: Dict[str, Metric], historic_values: Dict[str, object]):
        source_metric_values = metrics.get("source_metric").value
        target_metric_values = metrics.get("target_metric").value

        def compare_func(x, y, level=None):
            try:
                for i in range(0, len(self.source_key_columns)):
                    if x[self.source_key_columns[i]] != y[self.target_key_columns[i]]:
                        return False
                return True
            except KeyError:
                raise CannotCompare() from None

        diff = DeepDiff(
            source_metric_values,
            target_metric_values,
            ignore_order=True,
            iterable_compare_func=compare_func if self.source_key_columns and self.target_key_columns else None,
        )

        from soda.scan import verbose

        if verbose:
            from pprint import pprint

            pprint(diff)

        changed = 0
        added = 0
        removed = 0

        if diff:
            allow_samples = True
            src_offending_columns = []
            tgt_offending_columns = []

            src_tgt_cols = []
            for i in range(0, len(self.source_key_columns)):
                src_tgt_cols.append(f"{self.source_key_columns[i]} ({self.target_key_columns[i]})")
            samples_schema = src_tgt_cols + ["event", "old value", "new value"]
            samples = []

            is_column_excluded = self.data_source_scan.data_source.is_column_excluded
            src_table = self.metrics["source_metric"].partition.table.table_name
            tgt_table = self.metrics["target_metric"].partition.table.table_name

            for src_column in self.source_key_columns:
                if is_column_excluded(src_table, src_column):
                    src_offending_columns.append(src_column)
                    allow_samples = False

            for tgt_column in self.target_key_columns:
                if is_column_excluded(tgt_table, tgt_column):
                    tgt_offending_columns.append(tgt_column)
                    allow_samples = False

            if "values_changed" in diff:
                changed = len(diff["values_changed"])

                for key, row_diff in diff["values_changed"].items():
                    samples.append(
                        self._diff_changed_to_sample(
                            self._diff_parse_key(key), row_diff, source_metric_values, target_metric_values
                        )
                    )

            if "iterable_item_added" in diff:
                added = len(diff["iterable_item_added"])

                for key, row_diff in diff["iterable_item_added"].items():
                    samples.append(
                        self._diff_added_to_sample(
                            self._diff_parse_key(key), row_diff, source_metric_values, target_metric_values
                        )
                    )

            if "iterable_item_removed" in diff:
                removed = len(diff["iterable_item_removed"])

                for key, row_diff in diff["iterable_item_removed"].items():
                    samples.append(
                        self._diff_removed_to_sample(
                            self._diff_parse_key(key), row_diff, source_metric_values, target_metric_values
                        )
                    )

            if allow_samples and samples:
                sampler: Sampler = self.data_source_scan.scan._configuration.sampler
                sample_context = SampleContext(
                    sample=InMemorySample(samples, samples_schema),
                    sample_name="failed rows",
                    query="",
                    data_source=self.data_source_scan.data_source,
                    partition=self.partition,
                    column=None,
                    scan=self.data_source_scan.scan,
                    logs=self.data_source_scan.scan._logs,
                    samples_limit=self.check_cfg.samples_limit,
                    passing_sql="",
                    check_name=self.name,
                )

                self.failed_rows_sample_ref = sampler.store_sample(sample_context)

        self.check_value = changed + added + removed
        self.set_outcome_based_on_check_value()

        self.outcome_dict = {
            "changed": changed,
            "added": added,
            "removed": removed,
            "source_count": len(source_metric_values),
            "target_count": len(target_metric_values),
        }

    def _diff_parse_key(self, key: str) -> dict[str, any]:
        import re

        parsed = {"index": None, "column": None}
        key_parts = re.findall(r"\['?(.*?)'?\]", key)

        if key_parts:
            # The first part is always the index
            parsed["index"] = int(key_parts[0])

            if len(key_parts) > 1:
                # Second part is the column name
                parsed["column"] = key_parts[1]
        return parsed

    def _diff_changed_to_sample(
        self, key_parts: list[str], row_diff: dict, src_data: dict, tgt_data: dict
    ) -> list[str]:
        value = []

        if key_parts["index"] is not None:
            for key_column in self.source_key_columns:
                value.append(src_data[key_parts["index"]][key_column])

            value.extend(
                [
                    "changed",
                    self._dict_to_str_remove_top_brackets(row_diff["old_value"]),
                    self._dict_to_str_remove_top_brackets(row_diff["new_value"]),
                ]
            )

        return value

    def _diff_added_to_sample(self, key_parts: list[str], row_diff: dict, src_data: dict, tgt_data: dict) -> list[str]:
        value = []

        if key_parts["index"] is not None:
            for key_column in self.source_key_columns:
                value.append(tgt_data[key_parts["index"]][key_column])

            value.extend(["added", "", self._dict_to_str_remove_top_brackets(row_diff)])

        return value

    def _diff_removed_to_sample(
        self, key_parts: list[str], row_diff: dict, src_data: dict, tgt_data: dict
    ) -> list[str]:
        value = []

        if key_parts["index"] is not None:
            for key_column in self.source_key_columns:
                value.append(src_data[key_parts["index"]][key_column])

            value.extend(["removed", self._dict_to_str_remove_top_brackets(row_diff), ""])

        return value

    def _dict_to_str_remove_top_brackets(self, d: dict) -> str:
        s = str(d)

        if s.startswith("{"):
            s = s[1:]
        if s.endswith("}"):
            s = s[:-1]

        return s

    def get_log_diagnostic_dict(self) -> dict:
        d = super().get_log_diagnostic_dict()

        d["source_count"] = self.outcome_dict["source_count"]
        d["target_count"] = self.outcome_dict["target_count"]
        d["changed"] = self.outcome_dict["changed"]
        d["added"] = self.outcome_dict["added"]
        d["removed"] = self.outcome_dict["removed"]

        return d

    def get_cloud_diagnostics_dict(self) -> dict:
        cloud_diagnostics = super().get_cloud_diagnostics_dict()

        diagnostic_text = ""
        for key, value in self.outcome_dict.items():
            diagnostic_text += f"{key.replace('_', ' ').title()}, {value}\n"

        diagnostics_block = {
            "type": "csv",
            "title": "Diagnostics",
            "text": f"Event, Value\n{diagnostic_text}",
        }
        cloud_diagnostics["blocks"].append(diagnostics_block)

        return cloud_diagnostics

    def set_outcome_based_on_check_value(self):
        reconciliation_check_cfg = self.check_cfg
        if self.check_value is not None and reconciliation_check_cfg.has_threshold():
            reconciliation_check_cfg.resolve_thresholds(self.data_source_scan.scan.jinja_resolve)
            if reconciliation_check_cfg.fail_threshold_cfg and reconciliation_check_cfg.fail_threshold_cfg.is_bad(
                self.check_value
            ):
                self.outcome = CheckOutcome.FAIL
            elif reconciliation_check_cfg.warn_threshold_cfg and reconciliation_check_cfg.warn_threshold_cfg.is_bad(
                self.check_value
            ):
                self.outcome = CheckOutcome.WARN
            else:
                self.outcome = CheckOutcome.PASS

    def get_cloud_dict(self):
        d = super().get_cloud_dict()

        if "dataSource" in d:
            del d["dataSource"]

        if "table" in d:
            del d["table"]

        source_metric = self.metrics["source_metric"]
        target_metric = self.metrics["target_metric"]

        d["dataSources"] = [
            {
                "dataSource": source_metric.partition.data_source_scan.data_source.data_source_name,
                "table": source_metric.partition.table.table_name,
                "qualifier": "source",
            },
            {
                "dataSource": target_metric.partition.data_source_scan.data_source.data_source_name,
                "table": target_metric.partition.table.table_name,
                "qualifier": "target",
            },
        ]

        d["group"] = {
            "identity": self.check_cfg.reconciliation_configurations["group_identity"],
            "name": self.check_cfg.reconciliation_configurations["label"],
            "distinctLabel": self.name,
            "type": "reconciliation",
        }

        return d

    @property
    def name(self) -> str:
        name = super().name

        check_cfg: ReconciliationMetricCheckCfg = self.check_cfg
        if check_cfg.reconciliation_configurations["label"]:
            name = f"{check_cfg.reconciliation_configurations['label']} - {name}"

        return name
